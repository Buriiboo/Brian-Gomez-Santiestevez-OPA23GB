{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import streamlit as st\n",
    "from bs4 import BeautifulSoup\n",
    "from fpdf import FPDF\n",
    "from pathlib import Path\n",
    "\n",
    "# ExtractHtml class to get BeautifulSoup object from URL\n",
    "class ExtractHtml:\n",
    "    @staticmethod\n",
    "    def soup(url):\n",
    "        response = requests.get(url)\n",
    "        return BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# NBILinkScraper class to scrape links from the base URL\n",
    "class NBILinkScraper:\n",
    "    def __init__(self) -> None:\n",
    "        self.base_url = \"https://www.nbi-handelsakademin.se\"\n",
    "\n",
    "    def scrape(self, pathname, query=\"\"):\n",
    "        url = f\"{self.base_url}/{pathname}/{query}\"\n",
    "        all_links_raw = ExtractHtml.soup(url).select(\n",
    "            \".wpgb-card-media-content-bottom > a[href]\"\n",
    "        )\n",
    "        extracted_links = set(link[\"href\"] for link in all_links_raw)\n",
    "        extracted_links = {url.split(\"/\")[-2]: url for url in extracted_links}\n",
    "        return extracted_links\n",
    "\n",
    "# DataScraper class to scrape data from the extracted links\n",
    "class DataScraper:\n",
    "    def __init__(self, pathname, query=\"\") -> None:\n",
    "        self.links = NBILinkScraper().scrape(pathname, query)\n",
    "\n",
    "    def scrape(self, subject):\n",
    "        description_raw = ExtractHtml.soup(self.links[subject]).select(\n",
    "            \".wpb_text_column span, p,h4+ul li\"\n",
    "        )\n",
    "        description = \" \".join(\n",
    "            [\n",
    "                raw.text\n",
    "                for raw in description_raw\n",
    "                if not \"\\xa0\" in raw.get_text()  # or \"@\" in raw.text)\n",
    "            ]\n",
    "        )\n",
    "        return description\n",
    "\n",
    "# Specific scrapers for education and course pages\n",
    "class EducationScraper(DataScraper):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(\"utbildningar\", query=\"/?_programkurser=program\")\n",
    "\n",
    "class CourseScraper(DataScraper):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(\"kurser\")\n",
    "\n",
    "# ScrapeFormat class for scraping structured text and lists from a page\n",
    "class ScrapeFormat:\n",
    "    def __init__(self, pathname) -> None:\n",
    "        base_url = NBILinkScraper().base_url\n",
    "        url = f\"{base_url}/{pathname}\"\n",
    "        self.soup = ExtractHtml.soup(url)\n",
    "\n",
    "    def extract_text(self, tag):\n",
    "        text_list = [tag.text for tag in self.soup.select(tag)]\n",
    "        return \" \".join(text_list)\n",
    "\n",
    "    def extract_list(self, tag):\n",
    "        return [tag.text for tag in self.soup.select(tag)]\n",
    "\n",
    "# Specific scrapers for application and FAQ pages\n",
    "class ApplicationScraper:\n",
    "    def __init__(self, pathname=\"ansokan\") -> None:\n",
    "        self._scraper = ScrapeFormat(pathname)\n",
    "\n",
    "    @property\n",
    "    def description(self):\n",
    "        return self._scraper.extract_text(\"h1, h1~*\")\n",
    "\n",
    "    @property\n",
    "    def time_plan(self) -> list:\n",
    "        return self._scraper.extract_list(\"#tab-tidplan ul li, #tab-tidplan ul + p\")\n",
    "\n",
    "    @property\n",
    "    def available_educations(self) -> list:\n",
    "        return self._scraper.extract_list(\"#tab-ansok li\")\n",
    "\n",
    "    @property\n",
    "    def application_steps(self) -> list:\n",
    "        return self._scraper.extract_list(\"h3 a\")\n",
    "\n",
    "class FaqScraper:\n",
    "    def __init__(self, pathname=\"faq\") -> None:\n",
    "        self._scraper = ScrapeFormat(pathname)\n",
    "\n",
    "    @property\n",
    "    def faq(self) -> list:\n",
    "        return self._scraper.extract_list(\".toggle.default a, .toggle.default p\")\n",
    "\n",
    "# ExportScrapedText class to save text data into a file\n",
    "class ExportScrapedText:\n",
    "    def __init__(self, filename, content) -> None:\n",
    "        data_path = Path(__file__).parent / \"data\"\n",
    "        data_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        with open(data_path / filename, \"w\") as file:\n",
    "            file.write(content)\n",
    "\n",
    "# PDF creation using fpdf\n",
    "class PDF(FPDF):\n",
    "    def header(self):\n",
    "        self.set_font(\"Arial\", \"B\", 12)\n",
    "        self.cell(0, 10, \"Scraped Data\", 0, 1, \"C\")\n",
    "    \n",
    "    def footer(self):\n",
    "        self.set_y(-15)\n",
    "        self.set_font(\"Arial\", \"I\", 8)\n",
    "        self.cell(0, 10, f\"Page {self.page_no()}\", 0, 0, \"C\")\n",
    "\n",
    "def create_pdf(text, filename):\n",
    "    pdf = PDF()\n",
    "    pdf.add_page()\n",
    "    pdf.set_auto_page_break(auto=True, margin=15)\n",
    "    pdf.set_font(\"Arial\", size=12)\n",
    "    pdf.multi_cell(0, 10, text.encode('latin-1', 'replace').decode('latin-1'))\n",
    "    pdf.output(filename, 'F')\n",
    "\n",
    "# Example usage of the combined classes and functions\n",
    "if __name__ == \"__main__\":\n",
    "    education_scraper = EducationScraper()\n",
    "    description = education_scraper.scrape(\"some-education-subject\")\n",
    "    \n",
    "    # Save the scraped text into a PDF\n",
    "    create_pdf(description, \"output.pdf\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
